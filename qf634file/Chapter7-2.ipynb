{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617ee135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6deff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "data = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80540e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating Dependent Variable Vectors\n",
    "Y = data.iloc[:,-1].values\n",
    "X = data.iloc[:,3:13]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98c381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    1\n",
      "9996    1\n",
      "9997    0\n",
      "9998    1\n",
      "9999    0\n",
      "Name: Gender, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Generating Dependent Variable Vectors\n",
    "Y = data.iloc[:,-1].values\n",
    "X = data.iloc[:,3:13]\n",
    "X['Gender']=X['Gender'].map({'Female':0,'Male':1})\n",
    "### above is used instead of a more complicated package involving -- from sklearn.preprocessing import LabelEncoder\n",
    "### converts Female -- 0, Male -- 1, i.e. hot-encoding categorical variables\n",
    "print (X['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e436f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical variable Geography\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "### Geography is transformed into France -- 1,0,0; Spain -- 0,0,1; Germany -- 0,1,0.\n",
    "### Moreover -- this encoded vector of ones-zeros is now put in first 3 cols. Credit Score pushed to 4th col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3166a509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2      3    4     5    6          7    8    9    10         11\n",
       "0  1.0  0.0  0.0  619.0  0.0  42.0  2.0       0.00  1.0  1.0  1.0  101348.88\n",
       "1  0.0  0.0  1.0  608.0  0.0  41.0  1.0   83807.86  1.0  0.0  1.0  112542.58\n",
       "2  1.0  0.0  0.0  502.0  0.0  42.0  8.0  159660.80  3.0  1.0  0.0  113931.57\n",
       "3  1.0  0.0  0.0  699.0  0.0  39.0  1.0       0.00  2.0  0.0  0.0   93826.63\n",
       "4  0.0  0.0  1.0  850.0  0.0  43.0  2.0  125510.82  1.0  1.0  1.0   79084.10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert X to dataframe X1\n",
    "X1 = pd.DataFrame(X)\n",
    "X1.head()\n",
    "### Note there are 12 features including onehotencoder for the Geography feature-- \n",
    "### The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef915ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740ede9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850b84b",
   "metadata": {},
   "source": [
    "We call fit_transform() method on our training data and transform() method on our test data. Each feature in the training\n",
    "set is scaled to mean 0, variance 1. In sklearn.preprocessing.StandardScaler(), centering and scaling happens independently on each feature. The fit method is calculating the mean and variance of each of the features present in the data. The transform method is transforming all the features using the respective feature's mean and variance that are calculated in the statement\n",
    "before on X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43f1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the very first step while creating NNmodel -- you can rename this model. Here we are going to create NNmodel object \n",
    "### by using a certain class of Keras named Sequential. As a part of tensorflow 2.0, Keras is now integrated with \n",
    "### tensorflow and is now considered as a sub-library of tensorflow. The Sequential class is a part of the models module \n",
    "### of Keras library which is a part of the tensorflow library now. \n",
    "### It used to be \"import tensorflow as tf; from tensorflow import keras; from tensorflow.keras import layers\"\n",
    "### See documentation at https://keras.io/guides/sequential_model/\n",
    "\n",
    "#Initialising the NN model name -- NNmodel\n",
    "NNmodel = tf.keras.models.Sequential()\n",
    "### Sequential specifies to keras that the model NNmodel is created sequentially and the output of each layer added \n",
    "### is input to the next specified layer. Note that keras Sequential is not appropriate when the model has multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34730cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a network that has 1 hidden layer together with 1 input layer and 1 output layer. \n",
    "#Adding First Hidden Layer\n",
    "NNmodel.add(tf.keras.layers.Dense(units=2,activation=\"sigmoid\"))\n",
    "### units = 2 refer to 2 neurons in hidden layer \n",
    "### modelname.add is used to add a layer to the neural network -- need to specify as an argument what type of layer --\n",
    "### Dense is used to specify the fully connected layer - i.e. all neurons are forward connect to all forward layer nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab12edcf",
   "metadata": {},
   "source": [
    "Above -- first hidden layer is created using the Dense class which is part of the layers module. This class accepts 2 inputs:-\n",
    "(1) units:- number of neurons that will be present in the respective layer (2) activation:- specify which activation function to be used. This example uses first input as 2. There is no correct answer which is the right number of neurons in the layer -- trial and error. Not too large to be computationally impractical or redundant; not too small to be ineffective.\n",
    "For the second input, we try the sigmoid or logistic function as an activation function for hidden layers. We can also try “relu”[rectified linear unit]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "303997d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we create the output layer\n",
    "#Adding Output Layer\n",
    "NNmodel.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "### Only 1 output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4a623",
   "metadata": {},
   "source": [
    "For a binary classification problem as above, actual case output is 1 or 0. Hence we require only one neuron to output layer - output could be estimated probability of case actual output = 1. For multiclass classification problem, if the output contains m categories then we need to create m different neurons, one for each category. In the binary output case, the suitable activation function is the sigmoid function. For multiclass classification problem, the activation function is typically softmax. The softmax function predicts a multinomial probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70baaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### After creating the layers -- require compiling the NNmodel. Compiling allows the computer to run and understand the program \n",
    "### without the need of more fundamental steps in the programming. Compiling adds other elements or linking other libraries, and optimization,\n",
    "### such that after compiling the results are readily computed e.g. in a binary executable program as an output. \n",
    "#Compiling NNmodel\n",
    "NNmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "### Note optimizer here is a more sophisticated version of the Mean Square loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9d245",
   "metadata": {},
   "source": [
    "Compile method above accepts inputs: (1) optimizer:- specifies which optimizer to be used in order to perform stochastic gradient descent (2) error/loss function, e.g., 'binary_crossentropy' here. For multiclass classification, it should be categorical_crossentropy, (3) metrics - the performance metrics to use in order to compute performance. 'accuracy' is one such  performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51697cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a93b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 0s 706us/step - loss: 0.6830 - accuracy: 0.5587\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 547us/step - loss: 0.6223 - accuracy: 0.6796\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.5739 - accuracy: 0.7720\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 545us/step - loss: 0.5371 - accuracy: 0.7962\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.5099 - accuracy: 0.7974\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 535us/step - loss: 0.4902 - accuracy: 0.7972\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 520us/step - loss: 0.4761 - accuracy: 0.7972\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4659 - accuracy: 0.7972\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.4585 - accuracy: 0.7971\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4530 - accuracy: 0.7971\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 509us/step - loss: 0.4488 - accuracy: 0.7971\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 545us/step - loss: 0.4456 - accuracy: 0.7971\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 531us/step - loss: 0.4429 - accuracy: 0.7972\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 498us/step - loss: 0.4408 - accuracy: 0.7971\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 520us/step - loss: 0.4389 - accuracy: 0.7972\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 510us/step - loss: 0.4373 - accuracy: 0.7979\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4359 - accuracy: 0.7979\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4346 - accuracy: 0.7987\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.4334 - accuracy: 0.7997\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4324 - accuracy: 0.8014\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 517us/step - loss: 0.4313 - accuracy: 0.8030\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 512us/step - loss: 0.4304 - accuracy: 0.8045\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.4296 - accuracy: 0.8083\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4287 - accuracy: 0.8091\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 508us/step - loss: 0.4280 - accuracy: 0.8091\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4272 - accuracy: 0.8106\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4266 - accuracy: 0.8115\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 497us/step - loss: 0.4259 - accuracy: 0.8124\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 520us/step - loss: 0.4252 - accuracy: 0.8138\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4246 - accuracy: 0.8150\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4240 - accuracy: 0.8169\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 508us/step - loss: 0.4234 - accuracy: 0.8186\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 510us/step - loss: 0.4228 - accuracy: 0.8199\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 545us/step - loss: 0.4223 - accuracy: 0.8200\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.4217 - accuracy: 0.8206\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4212 - accuracy: 0.8223\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.4207 - accuracy: 0.8225\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 521us/step - loss: 0.4202 - accuracy: 0.8226\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 505us/step - loss: 0.4197 - accuracy: 0.8227\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 498us/step - loss: 0.4193 - accuracy: 0.8234\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 595us/step - loss: 0.4188 - accuracy: 0.8240\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 544us/step - loss: 0.4183 - accuracy: 0.8242\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4179 - accuracy: 0.8248\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 507us/step - loss: 0.4175 - accuracy: 0.8251\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4171 - accuracy: 0.8260\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4167 - accuracy: 0.8264\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4164 - accuracy: 0.8269\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.4160 - accuracy: 0.8264\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.4157 - accuracy: 0.8274\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 499us/step - loss: 0.4153 - accuracy: 0.8285\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 505us/step - loss: 0.4150 - accuracy: 0.8280\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 507us/step - loss: 0.4147 - accuracy: 0.8284\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4144 - accuracy: 0.8291\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4141 - accuracy: 0.8298\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 510us/step - loss: 0.4138 - accuracy: 0.8295\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4135 - accuracy: 0.8300\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.4133 - accuracy: 0.8304\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4131 - accuracy: 0.8306\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 521us/step - loss: 0.4128 - accuracy: 0.8314\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4126 - accuracy: 0.8319\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4123 - accuracy: 0.8317\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 519us/step - loss: 0.4121 - accuracy: 0.8322\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 536us/step - loss: 0.4119 - accuracy: 0.8319\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4117 - accuracy: 0.8324\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 545us/step - loss: 0.4115 - accuracy: 0.8322\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4114 - accuracy: 0.8322\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 531us/step - loss: 0.4112 - accuracy: 0.8320\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4109 - accuracy: 0.8321\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4108 - accuracy: 0.8329\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4106 - accuracy: 0.8328\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 511us/step - loss: 0.4105 - accuracy: 0.8329\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4103 - accuracy: 0.8329\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4102 - accuracy: 0.8335\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 531us/step - loss: 0.4100 - accuracy: 0.8329\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4099 - accuracy: 0.8334\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 536us/step - loss: 0.4098 - accuracy: 0.8330\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 533us/step - loss: 0.4096 - accuracy: 0.8335\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 545us/step - loss: 0.4095 - accuracy: 0.8340\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 522us/step - loss: 0.4094 - accuracy: 0.8339\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 531us/step - loss: 0.4092 - accuracy: 0.8336\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 521us/step - loss: 0.4091 - accuracy: 0.8336\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4090 - accuracy: 0.8338\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 544us/step - loss: 0.4089 - accuracy: 0.8341\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4088 - accuracy: 0.8344\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 507us/step - loss: 0.4087 - accuracy: 0.8341\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4086 - accuracy: 0.8353\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 544us/step - loss: 0.4085 - accuracy: 0.8347\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 520us/step - loss: 0.4084 - accuracy: 0.8344\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 535us/step - loss: 0.4083 - accuracy: 0.8349\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4082 - accuracy: 0.8351\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 533us/step - loss: 0.4082 - accuracy: 0.8350\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 527us/step - loss: 0.4081 - accuracy: 0.8353\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 514us/step - loss: 0.4080 - accuracy: 0.8355\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.4079 - accuracy: 0.8349\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4079 - accuracy: 0.8355\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 518us/step - loss: 0.4078 - accuracy: 0.8359\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 536us/step - loss: 0.4077 - accuracy: 0.8356\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 544us/step - loss: 0.4076 - accuracy: 0.8355\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 536us/step - loss: 0.4076 - accuracy: 0.8353\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.4075 - accuracy: 0.8361\n"
     ]
    }
   ],
   "source": [
    "#### Last step in creation of NNmodel NNmodel is trained on the training set here with Tensor-Keras .fit based on Compiler\n",
    "#Fitting NNmodel\n",
    "history=NNmodel.fit(X_train,Y_train,batch_size=100,epochs = 100)\n",
    "### Note that tf.keras.models.Sequential() by default uses glorot initializer -- drawing intial weights from a uniform \n",
    "### distribution -- see other possibilities in https://keras.io/api/layers/initializers/\n",
    "### Or you could try own customized wts inputs using\n",
    "### for layer in model.layers:\n",
    "###    init_layer_weight = [] # the weights yourself in this layer\n",
    "###    layer.set_weights(init_layer_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a74ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (100, 2)                  26        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (100, 1)                  3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 29\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fbefe2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5587499737739563, 0.6796249747276306, 0.7720000147819519, 0.7962499856948853, 0.7973750233650208, 0.797249972820282, 0.797249972820282, 0.797249972820282, 0.797124981880188, 0.797124981880188, 0.797124981880188, 0.797124981880188, 0.797249972820282, 0.797124981880188, 0.797249972820282, 0.7978749871253967, 0.7978749871253967, 0.7987499833106995, 0.7997499704360962, 0.8013749718666077, 0.8029999732971191, 0.8044999837875366, 0.8082500100135803, 0.8091250061988831, 0.8091250061988831, 0.8106250166893005, 0.8115000128746033, 0.812375009059906, 0.8137500286102295, 0.8149999976158142, 0.8168749809265137, 0.8186249732971191, 0.8198750019073486, 0.8199999928474426, 0.8206250071525574, 0.8222500085830688, 0.8224999904632568, 0.8226249814033508, 0.8227499723434448, 0.8233749866485596, 0.8240000009536743, 0.8242499828338623, 0.8247500061988831, 0.825124979019165, 0.8259999752044678, 0.8263750076293945, 0.8268749713897705, 0.8263750076293945, 0.8273749947547913, 0.828499972820282, 0.828000009059906, 0.828374981880188, 0.8291249871253967, 0.8297500014305115, 0.8295000195503235, 0.8299999833106995, 0.8303750157356262, 0.8306249976158142, 0.831375002861023, 0.8318750262260437, 0.8317499756813049, 0.8322499990463257, 0.8318750262260437, 0.8323749899864197, 0.8322499990463257, 0.8322499990463257, 0.8320000171661377, 0.8321250081062317, 0.8328750133514404, 0.8327500224113464, 0.8328750133514404, 0.8328750133514404, 0.8335000276565552, 0.8328750133514404, 0.8333749771118164, 0.8330000042915344, 0.8335000276565552, 0.8339999914169312, 0.8338750004768372, 0.8336250185966492, 0.8336250185966492, 0.8337500095367432, 0.8341249823570251, 0.8343750238418579, 0.8341249823570251, 0.8352500200271606, 0.8347499966621399, 0.8343750238418579, 0.8348749876022339, 0.8351250290870667, 0.8349999785423279, 0.8352500200271606, 0.8355000019073486, 0.8348749876022339, 0.8355000019073486, 0.8358749747276306, 0.8356249928474426, 0.8355000019073486, 0.8352500200271606, 0.8361250162124634]\n",
      "[0.6829895973205566, 0.6223207116127014, 0.5738764405250549, 0.5370952486991882, 0.5098568797111511, 0.49017348885536194, 0.4760788083076477, 0.4659035801887512, 0.45852184295654297, 0.4530121088027954, 0.4488244950771332, 0.4455735385417938, 0.4429287910461426, 0.4407687783241272, 0.43887457251548767, 0.43726134300231934, 0.43586423993110657, 0.4346007704734802, 0.4334399998188019, 0.43236464262008667, 0.43134453892707825, 0.4304419755935669, 0.42955949902534485, 0.42874711751937866, 0.42798662185668945, 0.4272315204143524, 0.4265683591365814, 0.4258873164653778, 0.4252324402332306, 0.42458581924438477, 0.4239843785762787, 0.42340824007987976, 0.42284831404685974, 0.4222605228424072, 0.4217482805252075, 0.4212161898612976, 0.42069151997566223, 0.42019331455230713, 0.4197223484516144, 0.41927069425582886, 0.41880762577056885, 0.4183298945426941, 0.4179188907146454, 0.4174808859825134, 0.4170866310596466, 0.41671496629714966, 0.4163528084754944, 0.41601139307022095, 0.4156527817249298, 0.4153268039226532, 0.41498446464538574, 0.41471850872039795, 0.41437286138534546, 0.4141347408294678, 0.413847953081131, 0.4135439097881317, 0.4132656455039978, 0.4130525290966034, 0.41278570890426636, 0.412596195936203, 0.4123322069644928, 0.4121304452419281, 0.4119352102279663, 0.41174864768981934, 0.41151121258735657, 0.41138118505477905, 0.41115185618400574, 0.4109480679035187, 0.41080108284950256, 0.410630464553833, 0.41046613454818726, 0.4102950692176819, 0.41017574071884155, 0.4099990427494049, 0.40986961126327515, 0.4097670912742615, 0.409604012966156, 0.40947628021240234, 0.4093678891658783, 0.40924984216690063, 0.4091138243675232, 0.4090210497379303, 0.40891262888908386, 0.408777117729187, 0.40874069929122925, 0.40862786769866943, 0.4085189700126648, 0.4084242582321167, 0.40833908319473267, 0.4082444906234741, 0.4081902801990509, 0.40810683369636536, 0.40797123312950134, 0.4079228639602661, 0.4078667461872101, 0.4078127145767212, 0.40769290924072266, 0.40760907530784607, 0.4075821340084076, 0.40749403834342957]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history['accuracy'])\n",
    "print(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy and loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'loss'], loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c57e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Below are the weights in the final iteration\n",
    "first_layer_weights = NNmodel.layers[0].get_weights()[0]\n",
    "first_layer_biases  = NNmodel.layers[0].get_weights()[1]\n",
    "second_layer_weights = NNmodel.layers[1].get_weights()[0]\n",
    "second_layer_biases  = NNmodel.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0f6f156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0222457  -0.1783295 ]\n",
      " [-0.17701912  0.8851328 ]\n",
      " [ 0.13505657  0.15091653]\n",
      " [ 0.09727661  0.03596907]\n",
      " [ 0.19355041 -0.6924882 ]\n",
      " [-2.9565787   0.02102099]\n",
      " [-0.02393755 -0.12498625]\n",
      " [-0.13618004  0.45022622]\n",
      " [-0.1208936  -0.39597127]\n",
      " [ 0.07495816  0.14370434]\n",
      " [-0.40983617 -2.1710153 ]\n",
      " [ 0.03662925  0.17995928]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(first_layer_weights)\n",
    "first_layer_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f38be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61959505 -0.6110315 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(first_layer_biases)\n",
    "first_layer_biases.shape  ### (2,) here basically means 2 elements in a 1-dim array. .T has no effect on 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "306e8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.764815 ]\n",
      " [ 1.9187759]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(second_layer_weights)\n",
    "second_layer_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5587208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.80749047]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(second_layer_biases)\n",
    "second_layer_biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a4a041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00150113 -0.58312392 -0.57273139 -1.55489968  0.91509065  0.10629772\n",
      "  -0.70174202 -0.26396987  0.80225696  0.64376017  0.97725852 -0.00249134]]\n"
     ]
    }
   ],
   "source": [
    "### Now we use the trained weights and biases to try to predict based on a new case\n",
    "tr=sc.transform([[1, 0, 0, 500, 1, 40, 3, 60000, 2, 1, 1, 100000]])\n",
    "print(tr)  ### tr.shape is (1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86520ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "[[0.10377286]]\n"
     ]
    }
   ],
   "source": [
    "### Example\n",
    "### Predicting result for Single Observation\n",
    "print(NNmodel.predict(tr))\n",
    "### note in each recompute -- this no. will change slightly because of the random initiation of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e89bf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63685913, -3.84694634]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now we compute the predicted prob of 1, manually\n",
    "tr.dot(first_layer_weights)  ### gives a 1 x 2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223820b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01726408 -4.45797782]]\n"
     ]
    }
   ],
   "source": [
    "Flayerneurons_sum=tr.dot(first_layer_weights) + first_layer_biases\n",
    "print(Flayerneurons_sum)  ### 1 x 2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7512768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49568409 0.01145308]]\n"
     ]
    }
   ],
   "source": [
    "Flayerneurons_act=1/(1+np.exp(-Flayerneurons_sum))\n",
    "print(Flayerneurons_act)  ### 1 x 2 matrix -- output of neurons in hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f7f5c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.15598943]]\n"
     ]
    }
   ],
   "source": [
    "Slayerneurons_sum=Flayerneurons_act.dot (second_layer_weights)+second_layer_biases\n",
    "print(Slayerneurons_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7960c6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10377286]]\n"
     ]
    }
   ],
   "source": [
    "predprob=1/(1+np.exp(-Slayerneurons_sum))\n",
    "print(predprob) ### Note this is the same output as NNmodel.predict(tr)\n",
    "### This manual computation of the forward pass should have output same as in NNmodel.predict(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34a5ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 528us/step - loss: 0.4073 - accuracy: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4073300063610077, 0.8357499837875366]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now we use the trained NNmodel to predict output in X_train sample\n",
    "NNmodel.evaluate(X_train,Y_train)  ### evaluates the loss and accuracy as specified in the Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ba646c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 464us/step\n"
     ]
    }
   ],
   "source": [
    "### Now we use the trained NNmodel to predict output in X_train sample -- computing manually via .predict\n",
    "TE=NNmodel.predict(X_train)  ### note X_train has 8000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82ce3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f49c856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=(TE > 0.5).astype(int) ### Convert TE>0.5 == true ==> 1, False to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb651f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(h)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a697768",
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace all elements in numpy array of value 0 with value -1\n",
    "h[h==0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9d41502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " ...\n",
      " [-1]\n",
      " [-1]\n",
      " [-1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(h)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8b950e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace all elements in numpy array of value 0 with value -1\n",
    "Y_train1=Y_train\n",
    "Y_train1[Y_train1==0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53b50eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  1 ...  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec6af287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe3de8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6686 0.83575\n"
     ]
    }
   ],
   "source": [
    "J=np.multiply(Y_train1.T,h.T)  ### element by element multiplication\n",
    "c=np.count_nonzero(J > 0) \n",
    "print(c,c/8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bfab32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 547us/step - loss: 0.4025 - accuracy: 0.8335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4024539589881897, 0.8335000276565552]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now we use the trained NNmodel to predict output in X_test sample\n",
    "NNmodel.evaluate(X_test,Y_test)  ### evaluates the loss and accuracy as specified in the Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f34f4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 554us/step\n"
     ]
    }
   ],
   "source": [
    "### Now we use the trained NNmodel to predict output in X_test sample -- computing manually via .predict\n",
    "TE1=NNmodel.predict(X_test)  ### note X_test has 2000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d186532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667 0.8335\n"
     ]
    }
   ],
   "source": [
    "h1=(TE1 > 0.5).astype(int) ### Convert TE1>0.5 == true ==> 1, False to 0\n",
    "h1[h1==0]=-1\n",
    "Y_test1=Y_test\n",
    "Y_test1[Y_test1==0]=-1\n",
    "J1=np.multiply(Y_test1.T,h1.T)  ### element by element multiplication\n",
    "c1=np.count_nonzero(J1 > 0) \n",
    "print(c1,c1/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f724b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
