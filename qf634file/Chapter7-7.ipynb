{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a8d2c8",
   "metadata": {},
   "source": [
    "In this program, we use logistic regression to see how the features could affect the prob of 1, i.e. exit, and also do the sklearn logistic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617ee135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6deff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "data = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80540e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating Dependent Variable Vectors\n",
    "Y = data.iloc[:,-1].values\n",
    "X = data.iloc[:,3:13]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98c381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    1\n",
      "9996    1\n",
      "9997    0\n",
      "9998    1\n",
      "9999    0\n",
      "Name: Gender, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Generating Dependent Variable Vectors\n",
    "Y = data.iloc[:,-1].values\n",
    "X = data.iloc[:,3:13]\n",
    "X['Gender']=X['Gender'].map({'Female':0,'Male':1})\n",
    "### above is used instead of a more complicated package involving -- from sklearn.preprocessing import LabelEncoder\n",
    "### converts Female -- 0, Male -- 1, i.e. hot-encoding categorical variables\n",
    "print (X['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e436f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical variable Geography\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
    "X = np.array(ct.fit_transform(X))\n",
    "### Geography is transformed into France -- 1,0,0; Spain -- 0,0,1; Germany -- 0,1,0.\n",
    "### Moreover -- this encoded vector of ones-zeros is now put in first 3 cols. Credit Score pushed to 4th col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3166a509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Germany</th>\n",
       "      <th>CrScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Products</th>\n",
       "      <th>CrCard</th>\n",
       "      <th>Active</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   France  Spain  Germany  CrScore  Gender   Age  Tenure    Balance  Products  \\\n",
       "0     1.0    0.0      0.0    619.0     0.0  42.0     2.0       0.00       1.0   \n",
       "1     0.0    0.0      1.0    608.0     0.0  41.0     1.0   83807.86       1.0   \n",
       "2     1.0    0.0      0.0    502.0     0.0  42.0     8.0  159660.80       3.0   \n",
       "3     1.0    0.0      0.0    699.0     0.0  39.0     1.0       0.00       2.0   \n",
       "4     0.0    0.0      1.0    850.0     0.0  43.0     2.0  125510.82       1.0   \n",
       "\n",
       "   CrCard  Active     Salary  \n",
       "0     1.0     1.0  101348.88  \n",
       "1     0.0     1.0  112542.58  \n",
       "2     1.0     0.0  113931.57  \n",
       "3     0.0     0.0   93826.63  \n",
       "4     1.0     1.0   79084.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert X to dataframe X1\n",
    "X1 = pd.DataFrame(X)\n",
    "### Note there are 12 features including onehotencoder for the Geography feature-- \n",
    "### The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme\n",
    "### Renaming columns so they appear as variable names in regression output table\n",
    "X1.columns = ['France', 'Spain','Germany','CrScore','Gender','Age','Tenure','Balance','Products','CrCard','Active','Salary']\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef915ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740ede9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850b84b",
   "metadata": {},
   "source": [
    "We call fit_transform() method on our training data and transform() method on our test data. Each feature in the training\n",
    "set is scaled to mean 0, variance 1. In sklearn.preprocessing.StandardScaler(), centering and scaling happens independently on each feature. The fit method is calculating the mean and variance of each of the features present in the data. The transform method is transforming all the features using the respective feature's mean and variance that are calculated in the statement\n",
    "before on X_train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708f597",
   "metadata": {},
   "source": [
    "Logit regression basically finds the max log likelihood of Log L = sum_i { Y_i x Ln F(b'X_i) + (1-Y_i) x Ln (1-F(b'X_i)) }\n",
    "and F(b'X_i) = 1/(1+exp(-b'X_i)) is Prob (Y_i=1). Note X_i increases makes Prob(Y_i=1) increases to 1, while X_i decreases makes Prob(Y_i=1) decreases to 0. Logit (logistic) regression below shows coeff estimates of b. Note also max log L is minimizing loss function minus sum_i { Y_i x Ln F(b'X_i) + (1-Y_i) x Ln (1-F(b'X_i)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43f1db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429076\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 8000\n",
      "Model:                          Logit   Df Residuals:                     7988\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Fri, 21 Oct 2022   Pseudo R-squ.:                  0.1490\n",
      "Time:                        10:57:49   Log-Likelihood:                -3432.6\n",
      "converged:                       True   LL-Null:                       -4033.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.481e-251\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Constant      -1.6549      0.035    -47.918      0.000      -1.723      -1.587\n",
      "France        -0.1232   1.73e+06  -7.12e-08      1.000   -3.39e+06    3.39e+06\n",
      "Spain          0.2178   1.51e+06   1.44e-07      1.000   -2.95e+06    2.95e+06\n",
      "Germany       -0.0768   1.49e+06  -5.14e-08      1.000   -2.93e+06    2.93e+06\n",
      "CrScore       -0.0535      0.030     -1.771      0.077      -0.113       0.006\n",
      "Gender        -0.2657      0.030     -8.768      0.000      -0.325      -0.206\n",
      "Age            0.7477      0.030     24.800      0.000       0.689       0.807\n",
      "Tenure        -0.0279      0.030     -0.924      0.355      -0.087       0.031\n",
      "Balance        0.1694      0.036      4.715      0.000       0.099       0.240\n",
      "Products      -0.0403      0.031     -1.319      0.187      -0.100       0.020\n",
      "CrCard        -0.0367      0.030     -1.220      0.222      -0.096       0.022\n",
      "Active        -0.5499      0.032    -16.996      0.000      -0.613      -0.486\n",
      "Salary         0.0161      0.030      0.530      0.596      -0.043       0.076\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(Y_train,sm.add_constant(X_train))\n",
    "result=logit_model.fit()\n",
    "#print(result.summary())\n",
    "print(result.summary(xname=['Constant','France', 'Spain','Germany','CrScore','Gender','Age','Tenure','Balance','Products','CrCard','Active','Salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd76d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58bd67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1231805   0.21764563 -0.07679625 -0.05350094 -0.26540571  0.74686475\n",
      "  -0.02786673  0.16927536 -0.04035424 -0.03663908 -0.54912598  0.01607395]] [-1.6543875]\n"
     ]
    }
   ],
   "source": [
    "Lresult = LogReg.fit(X_train, Y_train)\n",
    "print(Lresult.coef_, Lresult.intercept_)\n",
    "### SKlearn logisticRegression adds regularization so the results are a bit different from the statsmodel package above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05cbc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lpredict=LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c947a108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "### Using Score method to obtain accuracy (% correct prediction) of model\n",
    "score = LogReg.score(X_test,Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8ed8a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Lpredict) ### shows prediction of 1 or else of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d71f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lpredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e602df8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625 0.8125\n"
     ]
    }
   ],
   "source": [
    "Lpredict1=Lpredict\n",
    "Lpredict1[Lpredict1==0]=-1\n",
    "Y_test1=Y_test\n",
    "Y_test1[Y_test1==0]=-1\n",
    "J1=np.multiply(Y_test1.T,Lpredict1.T)  ### element by element multiplication\n",
    "c1=np.count_nonzero(J1 > 0) \n",
    "print(c1,c1/2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
